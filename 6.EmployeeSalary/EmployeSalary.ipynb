{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"gpu2","language":"python","name":"gpu2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"name":"EmployeSalary.ipynb","private_outputs":true,"provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RwY_vK63Ok1C"},"source":["import numpy as np #Библиотека работы с массивами\n","import pandas as pd # Библиотека для работы с базами\n","\n","from tensorflow.keras.models import Sequential, Model # \n","from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten #\n","from tensorflow.keras import utils #Используем для to_categoricall\n","from tensorflow.keras.optimizers import Adam,Adadelta,SGD,Adagrad,RMSprop #\n","from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence #\n","from tensorflow.keras.preprocessing.sequence import pad_sequences #\n","from tensorflow.keras.callbacks import LambdaCallback # подключаем колбэки\n","\n","from sklearn.preprocessing import StandardScaler # \n","from sklearn.model_selection import train_test_split # Для разбивки на выборки\n","from sklearn.metrics import mean_squared_error, mean_absolute_error #\n","#from google.colab import files #Для загрузки своей картинки\n","\n","import random #Для генерации случайных чисел \n","import math # Для округления\n","#import os #Для работы с файлами \n","import re #\n","import matplotlib.pyplot as plt #\n","%matplotlib inline\n","\n","from IPython.display import clear_output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTGdnqLwOnzi"},"source":["from google.colab import drive # Подключаем диск\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HvUHKVybOk1F"},"source":["# Оценка зарплаты на базе HeadHunter"]},{"cell_type":"code","metadata":{"id":"zJeA7eGMO06g"},"source":["fixed_df = pd.read_csv('/content/drive/MyDrive/machine/Lesson6/hh_fixed.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uXQwmwZOk1G"},"source":["# Количество резюме и критерии\n","print(fixed_df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftOsXmczOk1H"},"source":["fixed_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pufZuKCHOk1I"},"source":["# Парсим базу"]},{"cell_type":"code","metadata":{"id":"EZOPCWgcOk1I"},"source":["##############################################\n","####Убрать кодировку в описаниях \\xa0 \\n\n","##############################################\n","fixed_df = fixed_df.drop(fixed_df.columns[0],axis = 1) # Убираем первый столбец с продублированными индексами. Он нам не нужен\n","\n","i=0\n","for j in range(12):  # Для каждого из столбцов таблицы\n","    for i in range(fixed_df.shape[0]): # По всем резюме\n","        if type(fixed_df.values[i][j])!=float: # если данные текстовые, то заменяем фрагменты кодировки ASCII на отсутствие символов\n","            fixed_df.values[i][j] = fixed_df.values[i][j].replace(\"\\xa0\",\"\")\n","            fixed_df.values[i][j] = fixed_df.values[i][j].replace(\"\\n\",\" \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQsTIZcZOk1J"},"source":["# Данные о поле и возрасте\n","def getParameterSexAge(arg):\n","  out = [0,0]\n","  #Если М, то 1. По умолчанию 0 - Ж\n","  if \"М\" in arg:\n","    out[0] = 1\n","  # текущий год - год рождения\n","  year_tec = 2020\n","  if (len(arg) > 7):\n","    out[1] = year_tec - int(re.findall(r'\\d{4}', arg)[0])\n","  return out\n","\n","# Полученный возраст превращаем в класс возрастной категории\n","def getParameterAgeVect(arg):\n","  outClass =int((arg-13)/5)\n","  outClass = max(0, min(10,outClass))\n","  # На выходе получаем вектор с нужной категорией возраста\n","  return list(utils.to_categorical(outClass, 11).astype('int'))\n","\n","\n","# Зарплата\n","def getParameterSalary(arg):\n","    num = arg\n","    # Сначала получаем чистое число, убираем лишние знаки\n","    if (type(num) == str):\n","        num = re.sub(' ','',num)\n","        num = re.sub('[а-яА-ЯёЁ]','',num)\n","        num = re.sub('[a-zA-Z]','',num)\n","        num = num.replace('.','')\n","        \n","        # Получаем чисто валюту, убираем цифры\n","        curr = re.sub('[0-9]','',arg)\n","        curr = curr.replace('.','').strip()\n","        \n","        # Конвертируем в рубли, если валюта\n","        if curr == 'USD':\n","           num = float(num)*65\n","        elif curr == 'KZT':\n","           num = float(num)*0.17\n","        elif curr=='грн':\n","           num = float(num)*2.6\n","        elif curr=='белруб':\n","           num = float(num)*30.5\n","        elif curr=='EUR':\n","           num = float(num)*70\n","        elif curr=='KGS':\n","           num = float(num)*0.9\n","        elif curr=='сум':\n","           num = float(num)*0.007\n","        elif curr=='AZN':\n","           num = float(num)*37.5\n","             \n","    salaryStr = int(num) \n","\n","    \n","    return salaryStr\n","\n","\n","# Данные о городе\n","def getParameterCity(arg):\n","  millionCities = \"Новосибирск Екатеринбург Нижний Новгород Казань Челябинск Омск Самара Ростов-на-Дону Уфа Красноярск Пермь Воронеж Волгоград\"\n","  sarg=arg.split(',')\n","  for item in sarg:\n","    item= item.strip()\n","    if item == \"Москва\":          return [1, 0, 0, 0]\n","    if item == \"Санкт-Петербург\": return [0, 1, 0, 0]\n","    if item in millionCities:     return [0, 0, 1, 0]\n","  return [0, 0, 0, 1]\n","\n","# Данные о желаемой занятости\n","def getParameterEmployment(arg):\n","  out= [0, 0, 0, 0]\n","  if (\"стажировка\" in arg):           out[0]=1\n","  if (\"частичная занятость\" in arg):  out[1]=1\n","  if (\"проектная работа\" in arg):     out[2]=1\n","  if (\"полная занятость\" in arg):     out[3]=1\n","  return out\n","\n","# Данные о желаемом графике работы\n","def getParameterSchedule(arg):\n","  out = [0, 0, 0, 0]\n","  if (\"гибкий график\" in arg):    out[0]=1\n","  if (\"полный день\" in arg):      out[1]=1\n","  if (\"сменный график\" in arg):   out[2]=1\n","  if (\"удаленная работа\" in arg): out[3]=1\n","  return out\n","\n","# Данные об образовании\n","def getParameterEducation(arg):\n","  out = [0, 0, 0, 0] #По умолчанию не указано\n","  if arg in \"Высшее Higher education\":  out[0] = 1\n","  if arg in \"Среднее специальное\":      out[1] = 1\n","  if arg in \"Неоконченное высшее\":      out[2] = 1\n","  if arg in \"Среднее образование\":      out[3] = 1\n","  return out\n","\n","# Данные об опыте работы\n","def getParameterExperience(arg):\n","  arg = str(arg)\n","  #Проверяем, если не пустая строка\n","  symbols = 0\n","  years = 0\n","  months = 0\n","  for s in arg:\n","    if (s != \" \"):\n","      symbols += 1\n","  \n","  #Находим индексы пробелов около фразы \"опыт работы\"\n","  if (symbols > 10):\n","      spacesIndexes = []\n","      index = 0\n","      while ((len(spacesIndexes) < 5) & (index < len(arg))):\n","          if (arg[index] == \" \"):\n","              spacesIndexes.append(index)\n","          index += 1\n","\n","      years = 0\n","      months = 0\n","      if (arg[spacesIndexes[2]+1] != \"м\"):\n","         if (len(spacesIndexes) >= 3):\n","            yearsStr = arg[spacesIndexes[1]:spacesIndexes[2]] # Записываем в строку значение лет\n","            years = int(yearsStr)\n","      \n","         if (len(spacesIndexes) >= 5):\n","            monthsStr = arg[spacesIndexes[3]:spacesIndexes[4]] # Записываем в строку значение месяцев\n","            if(arg[spacesIndexes[2]+1] == \"м\"):\n","                months = int(monthsStr)\n","      else:\n","        if (len(spacesIndexes) >= 3):\n","          monthsStr = arg[spacesIndexes[1]:spacesIndexes[2]]\n","          months = int(monthsStr)\n","      \n","  return 12*years+months\n","\n","# Категориальное представление опыта работы\n","def getParameterExperienceVector(arg):\n","  out = getParameterExperience(arg)\n","  outClass = 0\n","  if (out > 6): # если больше 6 месяцев\n","    outClass = 1\n","  if (out > 12): # если больше 12 месяцев\n","    outClass = 2\n","  if (out > 24): # если больше 24 месяцев\n","    outClass = 3\n","  if (out > 36): # если больше 36 месяцев\n","    outClass = 4\n","  if (out > 60): # если больше 60 месяцев\n","    outClass = 5\n","  if (out > 96): # если больше 96 месяцев\n","    outClass = 6\n","  if (out > 120): # если больше 120 месяцев\n","    outClass = 7\n","  if (out > 156): # если больше 156 месяцев\n","    outClass = 8\n","  if (out > 192): # если больше 192 месяцев\n","    outClass = 9 \n","  if (out > 240): # если больше 240 месяцев\n","    outClass = 10\n","  \n","  return list(utils.to_categorical(outClass, 11).astype('int'))\n","\n","# Извлекаем все параметры\n","def getAllParameters(val):\n","  result = getParameterSexAge(val[0])\n","  sex = result[0]  #getParameterSex() #параметры о поле\n","  age =getParameterAgeVect(result[1]) #параметры о возрасте\n","  city = getParameterCity(val[3]) #параметры о городе\n","  employment = getParameterEmployment(val[4]) #параметры о желаемой занятости\n","  shedule = getParameterSchedule(val[5]) #параметры о желаемом графике\n","  education = getParameterEducation(val[9]) #параметры об образовании\n","  experience = getParameterExperienceVector(val[6]) #параметры об опыте\n","  out = [] \n","  \n","# Склеиваем все параметры в вектор  \n","  out.append(sex)\n","  out += age\n","  out += city\n","  out += employment\n","  out += shedule\n","  out += education\n","  out += experience\n","  \n","  return out\n","\n","# Создаем тренировочную выборку\n","def get01Data(values):\n","  xTrain = []\n","  yTrain = []\n","  \n","  # Предсказывать будем зарплату\n","  for val in values:\n","    y = getParameterSalary(val[1])\n","    x = getAllParameters(val)\n","    xTrain.append(x)\n","    yTrain.append(y/1000)\n","  \n","  xTrain = np.array(xTrain)\n","  yTrain = np.array(yTrain)\n","\n","  \n","  return (xTrain, yTrain)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8YG2Ac4Ok1M"},"source":["(xTrain01, yTrain) = get01Data(fixed_df.values) # Извлекаем значения загруженного набора данных"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1L90I6A3Ok1M"},"source":["## Нейронка по простым данным"]},{"cell_type":"code","metadata":{"id":"t3Lm41K1Ok1N"},"source":["# Обучаем модель полученными данными\n","model = Sequential()\n","model.add(BatchNormalization(input_shape=(xTrain01.shape[1],)))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(1000, activation='tanh'))\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","model.compile(optimizer=Adam(lr=1e-5), loss='mse', metrics=['mae'])\n","\n","history = model.fit(xTrain01, \n","                    yTrain, \n","                    epochs=50, \n","                    batch_size=32,\n","                    validation_split=0.15, \n","                    verbose=2)\n","\n","plt.plot(history.history['mae'], \n","         label='Средняя абсолютная ошибка на обучающем наборе')\n","plt.plot(history.history['val_mae'], \n","         label='Средняя абсолютная ошибка на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Средняя абсолютная ошибка')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmBJwmXWOk1N"},"source":["# Делаем предсказание и приводим его к начальному виду\n","pred = model.predict(xTrain01)\n","pred = pred.flatten()\n","# Среднее значение ошибки \n","delta = pred - yTrain\n","absDelta = abs(delta)\n","print(sum(absDelta) / len(absDelta))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-2AeCYJT2lp"},"source":["# В качестве нормализации данных используем готовую библиотеку \n","yScaler = StandardScaler()\n","\n","# Скармливаем объекту двумерный вектор\n","yScaler.fit(yTrain.reshape(-1, 1))\n","\n","# Нормализуем по нормальному распределению\n","yTrainScaled = yScaler.transform(yTrain.reshape(-1, 1))\n","\n","print(yTrainScaled.shape)\n","print(yTrain[1])\n","print(yTrainScaled[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dFzKwOWT5DX"},"source":["# Обучаем модель стандартизированными данными\n","modelS = Sequential()\n","modelS.add(BatchNormalization(input_shape=(xTrain01.shape[1],)))\n","modelS.add(Dense(128, activation='relu'))\n","modelS.add(Dense(1000, activation='tanh'))\n","modelS.add(Dense(100, activation='relu'))\n","modelS.add(Dense(1, activation='linear'))\n","\n","modelS.compile(optimizer=Adam(lr=1e-5), loss='mse', metrics=['mae'])\n","\n","history = modelS.fit(xTrain01, \n","                    yTrainScaled, \n","                    epochs=50, \n","                    batch_size=64,\n","                    validation_split=0.15, \n","                    verbose=2)\n","\n","plt.plot(history.history['mae'], \n","         label='Средняя абсолютная ошибка на обучающем наборе')\n","plt.plot(history.history['val_mae'], \n","         label='Средняя абсолютная ошибка на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Средняя абсолютная ошибка')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQhdZmCOT7HP"},"source":["# Делаем предсказание и приводим его к начальному виду\n","pred = modelS.predict(xTrain01)\n","predUnscaled = yScaler.inverse_transform(pred).flatten()\n","\n","# Среднее значение ошибки \n","delta = predUnscaled - yTrain\n","absDelta = abs(delta)\n","print(sum(absDelta) / len(absDelta))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XqvBJ_UBT91v"},"source":["## Оценка результатов"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-NBO8jJUDNn"},"source":["yy = model.predict(xTrain01) # Результат для всего тренировочного набора"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ttzedVLUGwv"},"source":["n = 10\n","for i in range(n):\n","  print('Реальное значение - ',yTrain[i], \" Предсказанное значение - \", yy[i][0], \" Разница - \", abs(yTrain[i]-yy[i][0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jxd20O_JURlc"},"source":["##Используем простые текстовые данные\n"]},{"cell_type":"code","metadata":{"id":"M6iRCYwgUJMH"},"source":["# Выкачиваем данные по профессиям\n","def getXTrainTProf(values):\n","  xTrainTProf = []\n","  \n","  for val in values:\n","    currText = \"\"\n","    if (type(val[2]) != float):\n","      currText += val[2]\n","    if (type(val[7]) != float):\n","      currText += \" \" + val[7]\n","    \n","    xTrainTProf.append(currText)\n","  \n","  xTrainTProf = np.array(xTrainTProf)\n","  \n","  return xTrainTProf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufyoZ48AUT8v"},"source":["# Вытаскиваем професии для выборки\n","xTrainTProf = getXTrainTProf(fixed_df.values) \n","print(xTrainTProf[123]) # пример профессии 11го резюме"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZShONllYUWWP"},"source":["#################\n","#Преобразовываем текстовые данные в числовые/векторные для обучения нейросетью\n","#################\n","\n","maxWordsCount = 10000 #определяем макс.кол-во слов/индексов, учитываемое при обучении текстов\n","\n","#для этого воспользуемся встроенной в Keras функцией Tokenizer для разбиения текста и превращения в матрицу числовых значений\n","tokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&()*+,-–—./:;<=>?@[\\\\]^_`{|}~\\t\\n\\xa0', lower=True, split=' ', oov_token='unknown', char_level=False)\n","#выше задаем параметры:\n","#(num_words=maxWordsCount) - определяем макс.кол-во слов/индексов, учитываемое при обучении текстов\n","#(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n') - избавляемся от ненужных символов\n","#(lower=True) - приводим слова к нижнему регистру\n","#(split=' ') - разделяем слова по пробелу\n","#(char_level=False) - просим токенайзер не удалять однобуквенные слова\n","\n","tokenizer.fit_on_texts(xTrainTProf) # \"скармливаем\" наши тексты, т.е даём в обработку методу, который соберет словарь частотности\n","items = list(tokenizer.word_index.items())  #Вытаскиваем индексы слов для просмотра"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ps37XO2tUXgv"},"source":["#преобразовываем текст в последовательность индексов согласно частотному словарю\n","xTrainProfIndexes = tokenizer.texts_to_sequences(xTrainTProf) #обучающие тесты в индексы"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNKo2KmiUblE"},"source":["## Создание обучающей и проверочной выборки"]},{"cell_type":"code","metadata":{"id":"fMPPvzwPUYw-"},"source":["# Преобразовываем полученные выборки из последовательности индексов в матрицы нулей и единиц по принципу Bag of Words\n","xTrainProf01 = tokenizer.sequences_to_matrix(xTrainProfIndexes) # Подаем xTrain в виде списка чтобы метод успешно сработал\n","print(xTrainProf01.shape)                                       # Размер обучающей выборки, сформированной по Bag of Words\n","print(xTrainProf01[0][0:100])        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atG87JTFUdtx"},"source":["n = 0\n","print(xTrainTProf[n])       # Профессия\n","print(xTrainProfIndexes[n]) # Профессия через индексы"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBvqV9EVUewv"},"source":["xTrainProf01.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_JMFmLx-UiaY"},"source":["##Обучаем нейронку на простых текстовых данных"]},{"cell_type":"code","metadata":{"id":"I3Dv3m1xUfwH"},"source":["# Предсказываем по предыдущей работе и желаемой\n","modelTProf = Sequential()\n","modelTProf.add(Dense(20, activation='relu', input_dim=(xTrainProf01.shape[1]) ) )\n","modelTProf.add(Dense(500, activation='relu'))\n","modelTProf.add(Dense(1, activation='linear'))\n","\n","modelTProf.compile(optimizer=Adagrad(lr=1e-3), loss='mse', metrics=['mae'])\n","\n","history = modelTProf.fit(xTrainProf01[:50000], \n","                    yTrain[:50000], \n","                    batch_size=20,\n","                    epochs=50, \n","                    #validation_split=0.1, \n","                    validation_data=(xTrainProf01[50000:], yTrain[50000:]),\n","                    verbose=1, shuffle=True)\n","\n","plt.plot(history.history['mae'], \n","         label='Средняя абсолютная ошибка на обучающем наборе')\n","plt.plot(history.history['val_mae'], \n","         label='Средняя абсолютная ошибка на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Средняя абсолютная ошибка')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS4rrBAtUkDH"},"source":["del xTrainProf01 # Удаляем переменную, иначе дальше может вылететь из-за нехватки памяти"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9tgaA4iRUpJN"},"source":["##Загружаем сложные текстовые данные"]},{"cell_type":"code","metadata":{"id":"iS_6UioHUmg_"},"source":["# Выкачиваем данные по резюме\n","def getXTrainTRez(values):\n","  xTrainTRez = []\n","  \n","  for val in values:\n","    currText = \"\"\n","    if (type(val[6]) != float):\n","      currText += val[6]\n","    \n","    xTrainTRez.append(currText)\n","  \n","  xTrainTRez = np.array(xTrainTRez)\n","  \n","  return xTrainTRez"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKa7km-RUq-Q"},"source":["# Вытаскиваем резюме для выборки\n","xTrainTRez = getXTrainTRez(fixed_df.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRqq6ABJUsen"},"source":["print(xTrainTRez[10]) # Пример профессии 11го резюме"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAZtfiOjUuEH"},"source":["#################\n","#Преобразовываем текстовые данные в числовые/векторные для обучения нейросетью\n","#################\n","\n","maxWordsCount = 5000 #определяем макс.кол-во слов/индексов, учитываемое при обучении текстов\n","\n","#для этого воспользуемся встроенной в Keras функцией Tokenizer для разбиения текста и превращения в матрицу числовых значений\n","tokenizer = Tokenizer(num_words=maxWordsCount, filters='!\"#$%&()*+,-–—./:;<=>?@[\\\\]^_`{|}~\\t\\n\\xa0', lower=True, split=' ', oov_token='unknown', char_level=False)\n","#выше задаем параметры:\n","#(num_words=maxWordsCount) - определяем макс.кол-во слов/индексов, учитываемое при обучении текстов\n","#(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n') - избавляемся от ненужных символов\n","#(lower=True) - приводим слова к нижнему регистру\n","#(split=' ') - разделяем слова по пробелу\n","#(char_level=False) - просим токенайзер не удалять однобуквенные слова\n","\n","tokenizer.fit_on_texts(xTrainTRez)         # \"скармливаем\" наши тексты, т.е даём в обработку методу, который соберет словарь частотности\n","items = list(tokenizer.word_index.items()) # Вытаскиваем индексы слов для просмотра"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FG7K_2mbUvJf"},"source":["# Преобразовываем текст в последовательность индексов согласно частотному словарю\n","xTrainRezIndexes = tokenizer.texts_to_sequences(xTrainTRez) # Обучающие тесты в индексы"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6GVVf_XxUwqf"},"source":["## Создание обучающей и проверочной выборки\n"]},{"cell_type":"code","metadata":{"id":"D-hRf9ObUwUH"},"source":["xTrainRez01 = tokenizer.sequences_to_matrix(xTrainRezIndexes) # Подаем xTrain в виде списка чтобы метод успешно сработал\n","print(xTrainRez01.shape)                                      # Размер обучающей выборки, сформированной по Bag of Words\n","print(xTrainRez01[0][0:100])    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yq-BuW1IU0Yf"},"source":["print(xTrainRez01.shape) # Размер выборки самых частых слов\n","print(xTrainRez01[555]) # Пример из отформатированной выборки"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-5lkUnEIU3AZ"},"source":["##Обучаем нейронку на сложных текстовых данных"]},{"cell_type":"code","metadata":{"id":"GGxYUPbdU2zx"},"source":["# здесь в параметрах maxWordCount = 2000\n","modelTRez = Sequential()\n","modelTRez.add(Dense(20, activation='relu',input_dim=(xTrainRez01.shape[1])))\n","modelTRez.add(Dense(500, activation='relu'))\n","modelTRez.add(Dropout(0.3))\n","modelTRez.add(Dense(1, activation='linear'))\n"," \n","modelTRez.compile(optimizer=Adam(lr=1e-3), loss='mse', metrics=['mae'])\n"," \n","history = modelTRez.fit(xTrainRez01[:50000], \n","                    yTrain[:50000], \n","                    batch_size=20,\n","                    epochs=20, \n","                    validation_data=(xTrainRez01[50000:], yTrain[50000:]),\n","                    verbose=1, shuffle=True)\n"," \n","plt.plot(history.history['mae'], \n","         label='Средняя абсолютная ошибка на обучающем наборе')\n","plt.plot(history.history['val_mae'], \n","         label='Средняя абсолютная ошибка на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Средняя абсолютная ошибка')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3jY6SJ-U8rs"},"source":["##Составная нейронка"]},{"cell_type":"code","metadata":{"id":"2fEXXQmgU1R3"},"source":["input1 = Input((xTrain01.shape[1],))\n","#input2 = Input((xTrainProf01.shape[1],))\n","input3 = Input((xTrainRez01.shape[1],))\n","\n","x1 = BatchNormalization()(input1) # Создаем ветку х1\n","x1 = Dropout(0.5)(x1)\n","x1 = Dense(10, activation=\"relu\")(x1)\n","x1 = Dense(1000, activation=\"relu\")(x1)\n","x1 = Dense(100, activation = \"relu\")(x1)\n","\n","#x2 = BatchNormalization()(input2) # Создаем ветку х2\n","#x2 = Dense(25, activation=\"relu\")(input2)\n","#x2 = Dense(8, activation=\"tanh\")(x2)\n","#x2 = Dense(5, activation = \"elu\")(x2)\n","\n","#x3 = BatchNormalization()(input3) # Создаем ветку х3\n","x3 = Dense(1000, activation=\"tanh\")(input3)\n","x3 = Dense(20, activation = \"elu\")(x3)\n","x3 = Dense(5, activation = \"elu\")(x3)\n","\n","x = concatenate([x1, x3]) # Объединяем все три ветки\n","\n","x = Dense(15, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(1, activation='relu')(x) # Финальный нейрон, делает регрессию\n","\n","model = Model((input1, input3), x) # В Model загружаем стартовые и последнюю точки \n","\n","model.compile(optimizer=Adam(lr=1e-3), loss='mse', metrics=['mae'])\n","\n","history = model.fit([xTrain01[:50000], xTrainRez01[:50000]], \n","                    yTrain[:50000], \n","                    epochs= 80, \n","                    validation_data=([xTrain01[50000:], xTrainRez01[50000:]], \n","                    yTrain[50000:]), \n","                    verbose=1, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JTrclrhU-Kn"},"source":["plt.plot(history.history['mae'], \n","         label='Средняя абсолютная ошибка на обучающем наборе')\n","plt.plot(history.history['val_mae'], \n","         label='Средняя абсолютная ошибка на проверочном наборе')\n","plt.xlabel('Эпоха обучения')\n","plt.ylabel('Средняя абсолютная ошибка')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLLZN35VVAgf"},"source":["yy = yTrain[50000:] # Зарплата\n","pred = model.predict([xTrain01[50000:], xTrainRez01[50000:]]) # Предсказанная зарплата\n","plt.scatter(yy, pred)\n","plt.xlabel('Правильные значение')\n","plt.ylabel('Предсказания')\n","plt.axis('equal')\n","plt.xlim(plt.xlim())\n","plt.ylim(plt.ylim())\n","plt.plot([-1000, 1000], [-1000, 1000])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0sbHCZjGVBh3"},"source":["del xTrainRez01, xTrainRezIndexes # Удаляем некоторые переменные, иначе дальше может вылететь из-за нехватки памяти"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"McKky7-9VD-v"},"source":[""],"execution_count":null,"outputs":[]}]}